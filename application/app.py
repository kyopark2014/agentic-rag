import streamlit as st 
import chat
import utils
import tool_use
import reflection
import planning

import cost_analysis as cost

logger = utils.CreateLogger("streamlit")

# title
st.set_page_config(page_title='Agentic RAG', page_icon=None, layout="centered", initial_sidebar_state="auto", menu_items=None)

mode_descriptions = {
    "ì¼ìƒì ì¸ ëŒ€í™”": [
        "ëŒ€í™”ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì±—ë´‡ê³¼ ì¼ìƒì˜ ëŒ€í™”ë¥¼ í¸ì•ˆíˆ ì¦ê¸¸ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "RAG": [
        "ê¸°ë³¸ì ì¸ RAGë¡œ Hallucinationì„ ìµœì†Œí™”í•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
    ],
    "Agentic RAG": [
        "Agentë¥¼ ì´ìš©í•´ RAGì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
    ],
    "Agentic RAG (Chat)": [
        "Agentë¥¼ ì´ìš©í•´ RAGì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ì „ ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë°˜ì˜í•œ ëŒ€í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    ],
    "Corrective RAG": [
        "Corrective RAGë¥¼ í™œìš©í•˜ì—¬ RAGì˜ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚µë‹ˆë‹¤."
    ],
    "Self RAG": [
        "Self RAGë¥¼ í™œìš©í•˜ì—¬ RAGì˜ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚µë‹ˆë‹¤."
    ],
    "Self Corrective RAG": [
        "Self Corrective RAGë¥¼ í™œìš©í•˜ì—¬ RAGì˜ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚µë‹ˆë‹¤."
    ],
    "Agent (Reflection)": [
        "Reflection Workflowë¥¼ ìˆ˜í–‰í•˜ëŠ” Agent êµ¬í˜„í•©ë‹ˆë‹¤."
    ],
    "Agent (Planning)": [
        "Planning Workflowë¥¼ ìˆ˜í–‰í•˜ëŠ” Agent êµ¬í˜„í•©ë‹ˆë‹¤."
    ],
    "ë²ˆì—­í•˜ê¸°": [
        "í•œêµ­ì–´ì™€ ì˜ì–´ì— ëŒ€í•œ ë²ˆì—­ì„ ì œê³µí•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì…ë ¥í•˜ë©´ ì˜ì–´ë¡œ, ì˜ì–´ë¡œ ì…ë ¥í•˜ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."        
    ],
    "ì´ë¯¸ì§€ ë¶„ì„": [
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "ë¹„ìš© ë¶„ì„": [
        "Cloud ì‚¬ìš©ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
    ]
}

with st.sidebar:
    st.title("ğŸ”® Menu")
    
    st.markdown(
        "Amazon Bedrockì„ ì´ìš©í•´ ë‹¤ì–‘í•œ í˜•íƒœì˜ ëŒ€í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤." 
        "ì—¬ê¸°ì—ì„œëŠ” ì¼ìƒì ì¸ ëŒ€í™”ì™€ ê°ì¢… íˆ´ì„ ì´ìš©í•´ Agentë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." 
        "ë˜í•œ ë²ˆì—­ì´ë‚˜ ë¬¸ë²• í™•ì¸ê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        "ì£¼ìš” ì½”ë“œëŠ” LangChainê³¼ LangGraphë¥¼ ì´ìš©í•´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        "ìƒì„¸í•œ ì½”ë“œëŠ” [Github](https://github.com/kyopark2014/agentic-rag)ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    )

    st.subheader("ğŸ± ëŒ€í™” í˜•íƒœ")
    
    # radio selection
    mode = st.radio(
        label="ì›í•˜ëŠ” ëŒ€í™” í˜•íƒœë¥¼ ì„ íƒí•˜ì„¸ìš”. ",options=["ì¼ìƒì ì¸ ëŒ€í™”", "RAG", "Agentic RAG", "Agentic RAG (Chat)", "Corrective RAG", "Self RAG", "Self Corrective RAG", "Agent (Reflection)", "Agent (Planning)", "ë²ˆì—­í•˜ê¸°", "ì´ë¯¸ì§€ ë¶„ì„", "ë¹„ìš© ë¶„ì„"], index=0
    )   
    st.info(mode_descriptions[mode][0])    
    # print('mode: ', mode)

    # model selection box
    if mode == 'ì´ë¯¸ì§€ ë¶„ì„':
        index = 2
    else:
        index = 0   
    modelName = st.selectbox(
        'ğŸ–Šï¸ ì‚¬ìš© ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”',
        ('Nova Pro', 'Nova Lite', 'Claude 3.7 Sonnet', 'Claude 3.5 Sonnet', 'Claude 3.0 Sonnet', 'Claude 3.5 Haiku'), index=index
    )
    
    uploaded_file = None
    st.subheader("ğŸ“‹ ë¬¸ì„œ ì—…ë¡œë“œ")
    if mode=='ì´ë¯¸ì§€ ë¶„ì„':
        st.subheader("ğŸŒ‡ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ìš”ì•½ì„ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["png", "jpg", "jpeg"])

    elif mode=='RAG' or mode=="Agentic RAG" or mode=="Agentic RAG (Chat)" or mode=="Corrective RAG" or mode=="Self RAG" or mode=="Self Corrective RAG":
        logger.info(f"fileId: {chat.fileId}")
        uploaded_file = st.file_uploader("RAGë¥¼ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["pdf", "doc", "docx", "ppt", "pptx", "png", "jpg", "jpeg", "txt", "py", "md", "csv"], key=chat.fileId)

    # debug checkbox
    select_debugMode = st.checkbox('Debug Mode', value=True)
    debugMode = 'Enable' if select_debugMode else 'Disable'
    #print('debugMode: ', debugMode)

    # multi region check box
    select_multiRegion = st.checkbox('Multi Region', value=False)
    multiRegion = 'Enable' if select_multiRegion else 'Disable'
    #print('multiRegion: ', multiRegion)

    # extended thinking of claude 3.7 sonnet
    select_reasoning = st.checkbox('Reasonking (only Claude 3.7 Sonnet)', value=False)
    reasoningMode = 'Enable' if select_reasoning and modelName=='Claude 3.7 Sonnet' else 'Disable'
    logger.info(f"reasoningMode: {reasoningMode}")

    # contextual embedding
    select_contextualEmbedding = st.checkbox('Contextual Embedding', value=False)
    contextualEmbedding = 'Enable' if select_contextualEmbedding else 'Disable'
    #print('contextualEmbedding: ', contextualEmbedding)

    # chart checkbox 
    selected_chart = st.checkbox('Chart', value=False)
    chart = 'Enable' if selected_chart else 'Disable'
    #print('chart: ', chart)

    chat.update(modelName, debugMode, multiRegion, contextualEmbedding, reasoningMode)
    
    st.success(f"Connected to {modelName}", icon="ğŸ’š")
    clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear")
    # print('clear_button: ', clear_button)

st.title('ğŸ”® '+ mode)  

if clear_button==True:
    chat.initiate()
    cost.cost_data = {}
    cost.visualizations = {}

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.greetings = False

# Display chat messages from history on app rerun
def display_chat_messages():
    """Print message history
    @returns None
    """
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if "images" in message:                
                for url in message["images"]:
                    logger.info(f"url: {url}")

                    file_name = url[url.rfind('/')+1:]
                    st.image(url, caption=file_name, use_container_width=True)
            st.markdown(message["content"])

display_chat_messages()

def show_references(reference_docs):
    if debugMode == "Enable" and reference_docs:
        with st.expander(f"ë‹µë³€ì—ì„œ ì°¸ì¡°í•œ {len(reference_docs)}ê°œì˜ ë¬¸ì„œì…ë‹ˆë‹¤."):
            for i, doc in enumerate(reference_docs):
                st.markdown(f"**{doc.metadata['name']}**: {doc.page_content}")
                st.markdown("---")

# Greet user
if not st.session_state.greetings:
    with st.chat_message("assistant"):
        intro = "ì•„ë§ˆì¡´ ë² ë“œë½ì„ ì´ìš©í•˜ì—¬ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í¸ì•ˆí•œ ëŒ€í™”ë¥¼ ì¦ê¸°ì‹¤ìˆ˜ ìˆìœ¼ë©°, íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìš”ì•½ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        st.markdown(intro)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": intro})
        st.session_state.greetings = True

if clear_button or "messages" not in st.session_state:
    st.session_state.messages = []        
    uploaded_file = None
    
    st.session_state.greetings = False
    st.rerun()

    chat.clear_chat_history()

if chart == 'Enable':
    if mode == 'Agentic RAG':
        col1, col2, col3 = st.columns([0.1, 0.25, 0.1])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-rag/main/contents/agentic-rag.png"
        col2.image(url)
    if mode == 'Agentic RAG (Chat)':
        col1, col2, col3 = st.columns([0.1, 0.25, 0.1])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-rag/main/contents/agentic-rag.png"
        col2.image(url)
    elif mode == 'Corrective RAG':
        col1, col2, col3 = st.columns([0.2, 0.3, 0.2])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-rag/main/contents/corrective-rag.png"
        col2.image(url)    
    elif mode == 'Self RAG':
        col1, col2, col3 = st.columns([0.1, 2.0, 0.1])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-rag/main/contents/self-rag2.png"
        col2.image(url)
    elif mode == 'Self Corrective RAG':
        col1, col2, col3 = st.columns([0.1, 2.0, 0.1])    
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-rag/main/contents/self-corrective-rag.png"
        col2.image(url)
    elif mode == 'Agent (Reflection)':
        col1, col2, col3 = st.columns([0.2, 0.3, 0.2])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-workflow/main/contents/reflection.png"
        col2.image(url)    
    elif mode == 'Agent (Planning)':
        col1, col2, col3 = st.columns([0.2, 0.3, 0.2])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-workflow/main/contents/planning.png"
        col2.image(url)

# Preview the uploaded image in the sidebar
file_name = ""
if uploaded_file and clear_button==False and not mode == 'ì´ë¯¸ì§€ ë¶„ì„':
    if uploaded_file.name:      
        chat.initiate()

        if debugMode=='Enable':
            status = 'ì„ íƒí•œ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.'
            logger.info(f"status: {status}")
            st.info(status)

        file_name = uploaded_file.name
        file_url = chat.upload_to_s3(uploaded_file.getvalue(), file_name)
        logger.info(f"file_url: {file_url}")
            
        status = f'ì„ íƒí•œ "{file_name}"ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.'
        # my_bar = st.sidebar.progress(0, text=status)
        
        # for percent_complete in range(100):
        #     time.sleep(0.2)
        #     my_bar.progress(percent_complete + 1, text=status)
        if debugMode=='Enable':
            logger.info(f"status: {status}")
            st.info(status)
    
        msg = chat.get_summary_of_uploaded_file(file_name, st)
        st.session_state.messages.append({"role": "assistant", "content": f"ì„ íƒí•œ ë¬¸ì„œ({file_name})ë¥¼ ìš”ì•½í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n\n{msg}"})    
        logger.info(f"msg: {msg}")
        st.rerun()
if uploaded_file and clear_button==False and mode == 'ì´ë¯¸ì§€ ë¶„ì„':
    st.image(uploaded_file, caption="ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)

    file_name = uploaded_file.name
    url = chat.upload_image_to_s3(uploaded_file.getvalue(), file_name)
    logger.info(f"url: {url}")

if clear_button==False and mode == 'ë¹„ìš© ë¶„ì„':
    st.subheader("ğŸ“ˆ Cost Analysis")

    if not cost.visualizations:
        cost.get_visualiation()

    if 'service_pie' in cost.visualizations:
        st.plotly_chart(cost.visualizations['service_pie'])
    if 'daily_trend' in cost.visualizations:
        st.plotly_chart(cost.visualizations['daily_trend'])
    if 'region_bar' in cost.visualizations:
        st.plotly_chart(cost.visualizations['region_bar'])

    with st.status("thinking...", expanded=True, state="running") as status:
        if not cost.cost_data:
            st.info("ë¹„ìš© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            cost_data = cost.get_cost_analysis()
            logger.info(f"cost_data: {cost_data}")
            cost.cost_data = cost_data
        else:
            if not cost.insights:        
                st.info("ì ì‹œë§Œ ê¸°ë‹¤ë¦¬ì„¸ìš”. ì§€ë‚œ í•œë‹¬ê°„ì˜ ì‚¬ìš©ëŸ‰ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                insights = cost.generate_cost_insights()
                logger.info(f"insights: {insights}")
                cost.insights = insights
            
            st.markdown(cost.insights)
            st.session_state.messages.append({"role": "assistant", "content": cost.insights})
            
# Always show the chat input
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    with st.chat_message("user"):  # display user message in chat message container
        st.markdown(prompt)

    st.session_state.messages.append({"role": "user", "content": prompt})  # add user message to chat history
    prompt = prompt.replace('"', "").replace("'", "")
    logger.info(f"prompt: {prompt}")

    with st.chat_message("assistant"):
        if mode == 'ì¼ìƒì ì¸ ëŒ€í™”':
            output = chat.general_conversation(prompt)            
            if reasoningMode=="Enable":
                with st.status("thinking...", expanded=True, state="running") as status:    
                    # extended thinking
                    if debugMode=="Enable":
                        chat.show_extended_thinking(st, output)

                    response = output.content
                    st.write(response)
                
            else:
                response = st.write_stream(output)
            
            logger.info(f"response: {response}")
            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)

        elif mode == 'RAG':
            with st.status("running...", expanded=True, state="running") as status:
                response, reference_docs = chat.get_answer_using_opensearch(prompt, st)     
                st.write(response)
                logger.info(f"response: {response}")            
                
                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        elif mode == 'Agentic RAG':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, image_url, reference_docs = tool_use.run_agent_executor(prompt, "Disable", st)
                st.write(response)
                logger.info(f"response: {response}")
                
                if len(image_url):
                    for url in image_url:
                        logger.info(f"url: {url}")

                        file_name = url[url.rfind('/')+1:]
                        st.image(url, caption=file_name, use_container_width=True)

                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "images": image_url if image_url else []
                })

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 
        
        elif mode == 'Agentic RAG (Chat)':
            with st.status("thinking...", expanded=True, state="running") as status:
                # revise_prompt = chat.revise_question(prompt, st)
                # response, image_url, reference_docs = tool_use.run_agent_executor(revise_prompt, "Enable", st)
                response, image_url, reference_docs = tool_use.run_agent_executor(prompt, "Enable", st)
                st.write(response)
                logger.info(f"response: {response}")
                
                if len(image_url):
                    for url in image_url:
                        logger.info(f"url: {url}")

                        file_name = url[url.rfind('/')+1:]
                        st.image(url, caption=file_name, use_container_width=True)

                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "images": image_url if image_url else []
                })

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 
                        
        elif mode == 'Corrective RAG':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_corrective_rag(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")

                if response.find('<thinking>') != -1:
                    logger.info(f"Remove <thinking> tag.")
                    response = response[response.find('</thinking>')+12:]
                    logger.info(f"response without tag: {response}")

                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        elif mode == 'Self RAG':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_self_rag(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")

                if response.find('<thinking>') != -1:
                    logger.info(f"Remove <thinking> tag.")
                    response = response[response.find('</thinking>')+12:]
                    logger.info(f"response without tag: {response}")

                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)

            show_references(reference_docs) 

        elif mode == 'Self Corrective RAG':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_self_corrective_rag(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")

                if response.find('<thinking>') != -1:
                    logger.info(f"Remove <thinking> tag.")
                    response = response[response.find('</thinking>')+12:]
                    logger.info(f"response without tag: {response}")

                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)

            show_references(reference_docs)         
        
        elif mode == 'Agent (Reflection)':
            with st.status("thinking...", expanded=True, state="running") as status:
                # esponse, reference_docs = chat.run_knowledge_guru(prompt, st)
                response, reference_docs = reflection.run_reflection(prompt, st)     
                st.write(response)
                logger.info(f"response: {response}")

                if response.find('<thinking>') != -1:
                    print('Remove <thinking> tag.')
                    logger.info(f"Remove <thinking> tag.")
                    response = response[response.find('</thinking>')+12:]
                    logger.info(f"response without tag: {response}")

                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        elif mode == 'Agent (Planning)':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = planning.run_planning(prompt, st)
                st.write(response)
                logger.info(f"response: {response}")

                if response.find('<thinking>') != -1:
                    logger.info(f"Remove <thinking> tag.")
                    response = response[response.find('</thinking>')+12:]
                    logger.info(f"response without tag: {response}")

                st.session_state.messages.append({"role": "assistant", "content": response})

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 
        
        elif mode == 'ë²ˆì—­í•˜ê¸°':
            response = chat.translate_text(prompt, modelName)
            st.write(response)

            st.session_state.messages.append({"role": "assistant", "content": response})

        elif mode == 'ì´ë¯¸ì§€ ë¶„ì„':
            if uploaded_file is None or uploaded_file == "":
                st.error("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
                st.stop()

            else:
                if modelName == "Claude 3.5 Haiku":
                    st.error("Claude 3.5 Haikuì€ ì´ë¯¸ì§€ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                else:
                    with st.status("thinking...", expanded=True, state="running") as status:
                        summary = chat.get_image_summarization(file_name, prompt, st)
                        st.write(summary)

                        st.session_state.messages.append({"role": "assistant", "content": summary})
                        # st.rerun()

        elif mode == 'ë¹„ìš© ë¶„ì„':
            with st.status("thinking...", expanded=True, state="running") as status:
                response = cost.ask_cost_insights(prompt)
                st.write(response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                # chat.save_chat_history(prompt, response)
        else:
            stream = chat.general_conversation(prompt)

            response = st.write_stream(stream)
            logger.info(f"response: {response}")

            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)